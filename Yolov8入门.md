# YOLOv8 å…¥é—¨

## 0.ç¯å¢ƒ

yolov8éœ€è¦æ”¯æŒcudaçš„gpuå’Œpytorchæ‰èƒ½æœ‰æ•ˆçš„å·¥ä½œã€‚

### 0.0 cudaå®‰è£…

**Windows**

é€šå¸¸æƒ…å†µä¸‹cudaä¼šåœ¨å®‰è£…nvidiaæ˜¾å¡é©±åŠ¨æ—¶è¢«å®‰è£…ï¼Œå¹¶ä¸éœ€è¦ç‹¬ç«‹å®‰è£…ã€‚å¯ä»¥é€šè¿‡åœ¨å‘½ä»¤è¡Œä¸‹é”®å…¥ä»¥ä¸‹æŒ‡ä»¤æ£€æŸ¥æ˜¯å¦å®‰è£…æœ‰cudaä¸cudaçš„ç‰ˆæœ¬ï¼š

```cmd
nvidia-smi
```

å¯å¾—åˆ°ä»¥ä¸‹ç»“æœï¼š

```cmd
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090 ...  WDDM  |   00000000:01:00.0  On |                  N/A |
| N/A   53C    P0             39W /  153W |    2262MiB /  16376MiB |     13%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
```

ç¬”è€…æ­¤å¤„çš„cudaç‰ˆæœ¬ä¸º12.4ã€‚

**jetson**

é€šè¿‡ä½¿ç”¨Nvidiaçš„sdk-manageråˆ·æœºçš„jetsonç³»åˆ—äº§å“åœ¨æˆåŠŸåˆ·æœºåéƒ½ä¼šè‡ªå¸¦cudaã€‚

åˆ·æœºååˆæ¬¡ä½¿ç”¨ï¼Œä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤å®‰è£…pipï¼š

```shell
sudo apt install python3-pip
```

é€šè¿‡pipå®‰è£…jtopï¼ˆä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿï¼‰ï¼š

```shell
sudo -H pip3 install jetson-stats -i https://pypi.tuna.tsinghua.edu.cn/simple
```

é‡å¯åä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤æŸ¥çœ‹çŠ¶æ€ï¼š

```shell
jtop
```

å¯ä»¥æŸ¥çœ‹å¯¹åº”çš„jetpackç‰ˆæœ¬ï¼š

![image-20240515162003636](./imgs/å±å¹•æˆªå›¾ 2024-05-15 161926.png)



### 0.1 pytorchå®‰è£…

**windows**

åœ¨[pytorchå®˜ç½‘](https://pytorch.org/)ä¸ŠæŸ¥æ‰¾å¯¹åº”ç‰ˆæœ¬å®‰è£…ï¼š

![image-20240515162428041](./imgs/å±å¹•æˆªå›¾ 2024-05-15 162422.png)

å®‰è£…å®Œæˆåä½¿ç”¨ä»¥ä¸‹pythonä»£ç æµ‹è¯•æ˜¯å¦å®‰è£…å®Œæˆï¼š

```python
import torch
print(torch.cuda.is_available())
```

è‹¥æ‰“å°ç»“æœä¸º`True`å³ä¸ºå®‰è£…æˆåŠŸã€‚

**jetson**

åœ¨[jetson zoo](https://elinux.org/Jetson_Zoo#PyTorch_.28Caffe2.29)å®˜ç½‘å¯»æ‰¾pytorchå®‰è£…åŒ…ï¼Œé€‰æ‹©ä¸jetpackå¯¹åº”çš„ç‰ˆæœ¬ä¸‹è½½ï¼š

![image-20240515173023991](./imgs/å±å¹•æˆªå›¾ 2024-05-15 172950.png)

ä¸‹è½½åä½¿ç”¨pipå®‰è£…ï¼ˆä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿä¾èµ–ä¸‹è½½ï¼‰ï¼š

```shell
pip install ./torch-*.py -i https://pypi.tuna.tsinghua.edu.cn/simple
```

å¹¶ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸ºrootç”¨æˆ·å®‰è£…ï¼š

```shell
sudo pip install ./torch-*.py -i https://pypi.tuna.tsinghua.edu.cn/simple
```

æŸ¥æ‰¾å’Œå½“å‰ç‰ˆæœ¬pytorchå¯¹åº”çš„torchvisionç‰ˆæœ¬ï¼ˆå¯å‚è€ƒpytorch[githubä¸»é¡µ](https://github.com/pytorch/vision)ï¼‰ï¼Œä»githubä»“åº“æ‹‰å–å¯¹åº”ç‰ˆæœ¬torchvisionï¼š

```shell
git clone --branch <ç‰ˆæœ¬å·> https://github.com/pytorch/vision torchvision
```

åœ¨torchvisionå·¥ç¨‹æ ¹ç›®å½•ä¸‹ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤æ‰“åŒ…whlæ–‡ä»¶ï¼š

```shell
sudo python3 setup.py sdist bdist_wheel
```

è¿›å…¥distç›®å½•æ‰¾åˆ°whlæ–‡ä»¶ï¼Œå¹¶å®‰è£…ï¼š

```shell
pip install torchvision-*.whl
```



### 0.2 Yolov8 å®‰è£…

ä½¿ç”¨pipå®‰è£…ï¼š

```sh
pip install ultralytics
```



## 1. ç›®æ ‡æ£€æµ‹ Detect

### 1.0 ç®€å•å°è¯•

ä½¿ç”¨ä»¥ä¸‹è„šæœ¬å³å¯ä½¿ç”¨`yolov8n`æ¨¡å‹è¿›è¡Œæ£€æµ‹ï¼š

```python
import cv2
import torch


from ultralytics import YOLO
from cv2 import getTickCount, getTickFrequency


# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")

# åŠ è½½ YOLOv8 æ¨¡å‹
model = YOLO("yolov8n.pt")
model.to(device)

# è·å–æ‘„åƒå¤´å†…å®¹ï¼Œå‚æ•° 0 è¡¨ç¤ºä½¿ç”¨é»˜è®¤çš„æ‘„åƒå¤´
cap = cv2.VideoCapture(0)

while cap.isOpened():
    loop_start = getTickCount()
    ret, frame = cap.read()  # è¯»å–æ‘„åƒå¤´çš„ä¸€å¸§å›¾åƒ

    if ret:
        results = model.predict(source=frame)[0]  # å¯¹å½“å‰å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹å¹¶æ˜¾ç¤ºç»“æœ
    annotated_frame = results.plot()

    cv2.imshow("img", annotated_frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):  # é€šè¿‡æŒ‰ä¸‹ 'q' é”®é€€å‡ºå¾ªç¯
        break

cap.release()  # é‡Šæ”¾æ‘„åƒå¤´èµ„æº
cv2.destroyAllWindows()  # å…³é—­OpenCVçª—å£
```

### 1.1 æ•°æ®é›†åˆ¶ä½œ

å»ºè®®ä½¿ç”¨anylabelingå®ç°åŠè‡ªåŠ¨æ ‡æ³¨ï¼š

```python
pip install anylabeling
```

![image-20240515180044117](./imgs/å±å¹•æˆªå›¾ 2024-05-15 180039.png)

ä½¿ç”¨anylabelingä¼šäº§ç”Ÿjsonæ ¼å¼çš„æ•°æ®ï¼Œéœ€è¦ä½¿ç”¨pythonè„šæœ¬è½¬æ¢ä¸ºyoloæ ¼å¼çš„txtæ–‡ä»¶ï¼š

```python
JSON_DIR = r".\rowdata\sensors\row_datasets\json" # åŸæ•°æ®è·¯å¾„
SAVE_DIR = r".\rowdata\sensors\row_datasets\txt"  # txtæ•°æ®å‚¨å­˜è·¯å¾„
CLASSES = "y_square,y_triangle,b_square,end,tx"   # ç›®æ ‡ç±»å‹åˆ—è¡¨


import json
import os
from tqdm import tqdm


def convert_label_json(json_dir: str, save_dir: str, classes: str):
    json_paths = os.listdir(json_dir)
    classes = classes.split(",")

    for json_path in tqdm(json_paths):
        # for json_path in json_paths:
        path = os.path.join(json_dir, json_path)
        with open(path, "r") as load_f:
            json_dict = json.load(load_f)
        h, w = json_dict["imageHeight"], json_dict["imageWidth"]

        # save txt path
        txt_path = os.path.join(save_dir, json_path.replace("json", "txt"))
        txt_file = open(txt_path, "w")

        for shape_dict in json_dict["shapes"]:
            if shape_dict["shape_type"] == "polygon":

                label = shape_dict["label"]
                label_index = classes.index(label)
                points = shape_dict["points"]

                points_nor_list = []

                for point in points:
                    points_nor_list.append(point[0] / w)
                    points_nor_list.append(point[1] / h)

                points_nor_list = list(map(lambda x: str(x), points_nor_list))
                points_nor_str = " ".join(points_nor_list)

                yolo_line = str(label_index) + " " + points_nor_str + "\n"
                txt_file.writelines(yolo_line)

            elif shape_dict["shape_type"] == "rectangle":
                label = shape_dict["label"]
                label_index = classes.index(label)
                points = shape_dict["points"]

                x1 = float(points[0][0])
                y1 = float(points[0][1])
                x2 = float(points[1][0])
                y2 = float(points[1][1])

                x_center = (x1 + x2) / 2.0 / w
                y_center = (y1 + y2) / 2.0 / h
                bbox_width = abs(x2 - x1) / w
                bbox_height = abs(y2 - y1) / h

                yolo_line = f"{label_index} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\n"
                txt_file.writelines(yolo_line)


if __name__ == "__main__":
    convert_label_json(JSON_DIR, SAVE_DIR, CLASSES)
```

ä½¿ç”¨pythonè„šæœ¬å°†å›¾ç‰‡å’Œæ ‡æ³¨æ•°æ®æŒ‰æ¯”ä¾‹åˆ‡åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼š

```python
# å°†å›¾ç‰‡å’Œæ ‡æ³¨æ•°æ®æŒ‰æ¯”ä¾‹åˆ‡åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
IMG_PATH = r".\rowdata\uuv_home\row_datasets\imgs" # å›¾åƒæ•°æ®å‚¨å­˜è·¯å¾„
TXT_DIR = r".\rowdata\uuv_home\row_datasets\txt"   # æ ‡æ³¨æ•°æ®å‚¨å­˜è·¯å¾„
SAVE_DIR = r".\rowdata\uuv_home\uuv_home"          # è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†æ•°æ®å‚¨å­˜è·¯å¾„

# æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹ï¼Œè®­ç»ƒé›†æ¯”ä¾‹ä¸éªŒè¯é›†æ¯”ä¾‹ï¼Œå‰©ä½™ä¸ºæµ‹è¯•é›†
TRAIN_PERCENT = 0.75 # è®­ç»ƒé›†æ¯”ä¾‹
VAL_PERCENT = 0.15   # éªŒè¯é›†æ¯”ä¾‹


import shutil
import random
import os
import argparse


# æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
def mkdir(path):
    if not os.path.exists(path):
        os.makedirs(path)


def main(image_dir, txt_dir, save_dir):
    # åˆ›å»ºæ–‡ä»¶å¤¹
    mkdir(save_dir)
    images_dir = os.path.join(save_dir, "images")
    labels_dir = os.path.join(save_dir, "labels")

    img_train_path = os.path.join(images_dir, "train")
    img_test_path = os.path.join(images_dir, "test")
    img_val_path = os.path.join(images_dir, "val")

    label_train_path = os.path.join(labels_dir, "train")
    label_test_path = os.path.join(labels_dir, "test")
    label_val_path = os.path.join(labels_dir, "val")

    mkdir(images_dir)
    mkdir(labels_dir)
    mkdir(img_train_path)
    mkdir(img_test_path)
    mkdir(img_val_path)
    mkdir(label_train_path)
    mkdir(label_test_path)
    mkdir(label_val_path)

    test_percent = 0

    total_txt = os.listdir(txt_dir)
    num_txt = len(total_txt)
    list_all_txt = range(num_txt)  # èŒƒå›´ range(0, num)

    num_train = int(num_txt * TRAIN_PERCENT)
    num_val = int(num_txt * VAL_PERCENT)
    num_test = num_txt - num_train - num_val

    train = random.sample(list_all_txt, num_train)
    # åœ¨å…¨éƒ¨æ•°æ®é›†ä¸­å–å‡ºtrain
    val_test = [i for i in list_all_txt if not i in train]
    # å†ä»val_testå–å‡ºnum_valä¸ªå…ƒç´ ï¼Œval_testå‰©ä¸‹çš„å…ƒç´ å°±æ˜¯test
    val = random.sample(val_test, num_val)

    print(
        "è®­ç»ƒé›†æ•°ç›®ï¼š{}, éªŒè¯é›†æ•°ç›®ï¼š{},æµ‹è¯•é›†æ•°ç›®ï¼š{}".format(
            len(train), len(val), len(val_test) - len(val)
        )
    )
    for i in list_all_txt:
        name = total_txt[i][:-4]

        srcImage = os.path.join(image_dir, name + ".jpg")
        srcLabel = os.path.join(txt_dir, name + ".txt")

        if i in train:
            dst_train_Image = os.path.join(img_train_path, name + ".jpg")
            dst_train_Label = os.path.join(label_train_path, name + ".txt")
            shutil.copyfile(srcImage, dst_train_Image)
            shutil.copyfile(srcLabel, dst_train_Label)
        elif i in val:
            dst_val_Image = os.path.join(img_val_path, name + ".jpg")
            dst_val_Label = os.path.join(label_val_path, name + ".txt")
            shutil.copyfile(srcImage, dst_val_Image)
            shutil.copyfile(srcLabel, dst_val_Label)
        else:
            dst_test_Image = os.path.join(img_test_path, name + ".jpg")
            dst_test_Label = os.path.join(label_test_path, name + ".txt")
            shutil.copyfile(srcImage, dst_test_Image)
            shutil.copyfile(srcLabel, dst_test_Label)


if __name__ == "__main__":
    main(IMG_PATH, TXT_DIR, SAVE_DIR)
```



### 1.2 æ¨¡å‹è®­ç»ƒ

åˆ›å»ºyamlæ ¼å¼çš„æ•°æ®é›†æè¿°æ–‡ä»¶ï¼š

```yaml
# æ•°æ®é›†æ ¹ç›®å½•
path: ./rowdata/sensors/sensors

# æ•°æ®é›†åˆ†å‰²
train: images/train
val: images/train
test: images/train

# ç±»åˆ«å
names:
  0: y_square
  1: y_triangle
  2: b_squar
  3: end
  4: tx

# ç±»åˆ«æ•°
nc: 5
```

åˆ›å»ºyamlæ ¼å¼çš„æ¨¡å‹æè¿°æ–‡ä»¶ï¼š

```yaml
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 5 # ç±»åˆ«æ•°
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024] # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768] # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512] # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512] # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
  - [-1, 3, C2f, [512]] # 12

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
  - [-1, 3, C2f, [256]] # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]] # cat head P4
  - [-1, 3, C2f, [512]] # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]] # cat head P5
  - [-1, 3, C2f, [1024]] # 21 (P5/32-large)

  - [[15, 18, 21], 1, Detect, [nc]] # Detect(P3, P4, P5)
```

ç¼–å†™pythonè„šæœ¬è®­ç»ƒï¼š

```python
DATASET_YAML_PATH = r".\datasets\sensors.yaml"
MODEL_YAML_PATH = r".\models\sensors.yaml"

SIZE = 640    # è¾“å…¥å›¾åƒå¤§å° SIZE*SIZE
EPOCHS = 100  # è®­ç»ƒæ¬¡æ•°

import torch

from ultralytics import YOLO

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")


# æ„å»ºæ¨¡å‹
model = YOLO(MODEL_YAML_PATH)

model.to(device) # åŠ è½½æ¨¡å‹è‡³GPU
model.load("weights/yolov8n.pt")  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹


if __name__ == "__main__":
    # è®­ç»ƒæ¨¡å‹
    results = model.train(data=DATASET_YAML_PATH, epochs=EPOCHS, imgsz=SIZE)
	# æµ‹è¯•æ¨¡å‹
    metrics = model.val()
```



### 1.3 æ¨¡å‹é¢„æµ‹

åŠ è½½æ¨¡å‹å¹¶ä½¿ç”¨gpuå®ç°æ¨¡å‹çš„é¢„æµ‹ï¼š

```python
import torch
from ultralytics import YOLO

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")

# åŠ è½½ YOLOv8 æ¨¡å‹
model = YOLO("weights/sensors.pt")
model.to(device)
```

ä»æ¨¡å‹ä¸­æå–ç›®æ ‡åç§°åˆ—è¡¨ï¼š

```python
name_list = model.names
```

ä½¿ç”¨`model.predict(source=frame)[0]`å¯¹å½“å‰å¸§è¿›è¡Œé¢„æµ‹ï¼š

```python
result = model.predict(source=frame)[0]
```

ä»¥numpyæ•°ç»„çš„å½¢å¼æå–é¢„æµ‹ç»“æœï¼š

```py
if result.boxes is not None:
    targets = result.boxes.data.cpu().numpy()
```

è¿™å°†ä¼šè·å–ä¸€ä¸ªç”±6ç»´å‘é‡æ„æˆçš„æ•°ç»„ï¼Œå¯ä»ä¸­æå–ç›®æ ‡åç§°ï¼š

```python
for t in targets:
    name = name_list[int(t[5])]
```

å¯ä»ä¸­æå–ç›®æ ‡å¯ä¿¡åº¦ï¼š

```python
for t in targets:
    conf = float(t[4])
```

å¯ä»ä¸­æå–ç›®æ ‡æ¡†çš„ä¸€å¯¹å¯¹è§’ç‚¹çš„Xä¸Yåæ ‡ï¼š

```python
for t in targets:
    box_xyxy =t[:4]
```



## 2. å›¾å½¢åˆ†å‰² Segment

### 2.0 ç®€å•å°è¯•

ä½¿ç”¨ä»¥ä¸‹è„šæœ¬å³å¯ä½¿ç”¨`yolov8n-seg`æ¨¡å‹è¿›è¡Œæ£€æµ‹ï¼š

 ```python
 import cv2
 import torch
 
 
 from ultralytics import YOLO
 from cv2 import getTickCount, getTickFrequency
 
 
 # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
 if torch.cuda.is_available():
     device = torch.device("cuda:0")
     print("Running on the GPU")
 else:
     device = torch.device("cpu")
     print("Running on the CPU")
 
 # åŠ è½½ YOLOv8 æ¨¡å‹
 model = YOLO("yolov8n-seg.pt")
 model.to(device)
 
 # è·å–æ‘„åƒå¤´å†…å®¹ï¼Œå‚æ•° 0 è¡¨ç¤ºä½¿ç”¨é»˜è®¤çš„æ‘„åƒå¤´
 cap = cv2.VideoCapture(0)
 
 while cap.isOpened():
     loop_start = getTickCount()
     ret, frame = cap.read()  # è¯»å–æ‘„åƒå¤´çš„ä¸€å¸§å›¾åƒ
 
     if ret:
         results = model.predict(source=frame)[0]  # å¯¹å½“å‰å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹å¹¶æ˜¾ç¤ºç»“æœ
     annotated_frame = results.plot()
 
     cv2.imshow("img", annotated_frame)
 
     if cv2.waitKey(1) & 0xFF == ord("q"):  # é€šè¿‡æŒ‰ä¸‹ 'q' é”®é€€å‡ºå¾ªç¯
         break
 
 cap.release()  # é‡Šæ”¾æ‘„åƒå¤´èµ„æº
 cv2.destroyAllWindows()  # å…³é—­OpenCVçª—å£
 ```



### 2.1 æ•°æ®é›†åˆ¶ä½œ

å»ºè®®ä½¿ç”¨anylabelingå®ç°åŠè‡ªåŠ¨æ ‡æ³¨ï¼š

```python
pip install anylabeling
```

![image-20240515183421009](./imgs/å±å¹•æˆªå›¾ 2024-05-15 183418.png)

anylabeling ä¼šäº§ç”Ÿjsonæ ¼å¼çš„æ–‡ä»¶ï¼Œéœ€è¦ä½¿ç”¨pythonè„šæœ¬å°†å…¶è½¬æ¢ä¸ºyoloçš„txtæ ¼å¼çš„æ ‡æ³¨æ•°æ®ï¼Œè„šæœ¬å¯ä½¿ç”¨  **1.1æ•°æ®é›†åˆ¶ä½œ** ä¸­çš„è½¬æ¢è„šæœ¬ã€‚

ä½¿ç”¨ **1.1æ•°æ®é›†åˆ¶ä½œ** ä¸­çš„pythonåˆ’åˆ†è„šæœ¬åˆ’åˆ†æ­¤å¤„çš„æ•°æ®é›†ã€‚



### 2.2 æ¨¡å‹è®­ç»ƒ

åˆ›å»ºyamlæ ¼å¼çš„æ•°æ®é›†æè¿°æ–‡ä»¶ï¼š

```yaml
# æ•°æ®é›†æ ¹ç›®å½•
path: ./rowdata/redline/redline

# æ•°æ®é›†åˆ†å‰²
train: images/train
val: images/val
test: images/test

# ç±»åˆ«
names:
  0: redline
```

åˆ›å»ºyamlæ ¼å¼çš„æ¨¡å‹æè¿°æ–‡ä»¶ï¼š

```yaml
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8-seg instance segmentation model. For Usage examples see https://docs.ultralytics.com/tasks/segment
 
# Parameters
nc: 1  # ç±»åˆ«æ•°
scales: # model compound scaling constants, i.e. 'model=yolov8n-seg.yaml' will call yolov8-seg.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]
  s: [0.33, 0.50, 1024]
  m: [0.67, 0.75, 768]
  l: [1.00, 1.00, 512]
  x: [1.00, 1.25, 512]
 
# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
 
# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12
 
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)
 
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)
 
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)
 
  - [[15, 18, 21], 1, Segment, [nc, 32, 256]]  # Segment(P3, P4, P5)
```

ç¼–å†™pythonè„šæœ¬è¿›è¡Œè®­ç»ƒï¼š

```python
DATASET_YAML_PATH = r".\datasets\redlines.yaml"
MODEL_YAML_PATH = r".\models\redlines.yaml"

SIZE = 640    # è¾“å…¥å›¾åƒå¤§å° SIZE*SIZE
EPOCHS = 100  # è®­ç»ƒæ¬¡æ•°

import torch

from ultralytics import YOLO

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")


# æ„å»ºæ¨¡å‹
model = YOLO(MODEL_YAML_PATH)

model.to(device) # åŠ è½½æ¨¡å‹è‡³GPU
model.load("weights/yolov8n-seg.pt")  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹


if __name__ == "__main__":
    # è®­ç»ƒæ¨¡å‹
    results = model.train(data=DATASET_YAML_PATH, epochs=EPOCHS, imgsz=SIZE)
	# æµ‹è¯•æ¨¡å‹
    metrics = model.val()
```



### 2.3 æ¨¡å‹é¢„æµ‹

åŠ è½½æ¨¡å‹å¹¶ä½¿ç”¨gpuå®ç°æ¨¡å‹çš„é¢„æµ‹ï¼š

```python
import torch
from ultralytics import YOLO

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")

# åŠ è½½ YOLOv8 æ¨¡å‹
model = YOLO("weights/sensors.pt")
model.to(device)
```

ä½¿ç”¨`model.predict(source=frame)[0]`å¯¹å½“å‰å¸§è¿›è¡Œé¢„æµ‹ï¼š

```python
result = model.predict(source=frame)[0]
```

ä»¥numpyçš„æ ¼å¼æå–å›¾åƒä¸­çš„æ©è†œï¼š

```python
if result.masks is not None:
    # load mask from predict resault
    mask_raw = result.masks[0].cpu().data.numpy().transpose(1, 2, 0)
    for mask_raw in result.masks:
        mask_raw += mask_raw.cpu().data.numpy().transpose(1, 2, 0)
```

æ­¤å¤„éœ€è¦è½¬ç½®æ©è†œçŸ©é˜µä»¥è·å–cv2æ ¼å¼çš„numpyçŸ©é˜µã€‚

å˜æ¢æ©è†œå¤§å°ï¼Œä»¥åŒ¹é…åŸå›¾åƒï¼ŒåŒæ—¶è½¬æ¢æ•°æ®æ ¼å¼ä¸º`numpy.int32`ä»¥æ–¹ä¾¿åç»­å¤„ç†ï¼š

```python
mask = cv2.resize(mask_raw, size, interpolation=cv2.INTER_LINEAR).astype(
    np.int32
)
```

è¿™æ ·å°±è·å–äº†ä¸€ä»½å’ŒåŸå›¾ç›¸åŒå¤§å°çš„æ©è†œï¼Œè¯¥æ©è†œä¸ºyolov8å¯¹ç›®æ ‡å›¾å½¢è¿›è¡Œå›¾å½¢åˆ†å‰²çš„ç»“æœã€‚



## 3. å…³é”®ç‚¹æ£€æµ‹ Pose

### 3.0 ç®€å•å°è¯•

ä½¿ç”¨ä»¥ä¸‹è„šæœ¬å³å¯ä½¿ç”¨`yolov8n-poseæ¨¡å‹è¿›è¡Œæ£€æµ‹ï¼š

 ```python
import cv2
import torch


from ultralytics import YOLO
from cv2 import getTickCount, getTickFrequency


# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")

# åŠ è½½ YOLOv8 æ¨¡å‹
model = YOLO("yolov8n-pose.pt")
model.to(device)

# è·å–æ‘„åƒå¤´å†…å®¹ï¼Œå‚æ•° 0 è¡¨ç¤ºä½¿ç”¨é»˜è®¤çš„æ‘„åƒå¤´
cap = cv2.VideoCapture(0)

while cap.isOpened():
    loop_start = getTickCount()
    ret, frame = cap.read()  # è¯»å–æ‘„åƒå¤´çš„ä¸€å¸§å›¾åƒ

    if ret:
        results = model.predict(source=frame)[0]  # å¯¹å½“å‰å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹å¹¶æ˜¾ç¤ºç»“æœ
    annotated_frame = results.plot()

    cv2.imshow("img", annotated_frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):  # é€šè¿‡æŒ‰ä¸‹ 'q' é”®é€€å‡ºå¾ªç¯
        break

cap.release()  # é‡Šæ”¾æ‘„åƒå¤´èµ„æº
cv2.destroyAllWindows()  # å…³é—­OpenCVçª—å£
 ```



### 3.1 åˆ¶ä½œæ•°æ®é›†

ä¸ºä¿æŒå’Œä¸Šæ–‡åŒä¸€ï¼Œä½¿ç”¨anylabelingæ ‡æ³¨ï¼Œ

![image-20240515190218385](./imgs/å±å¹•æˆªå›¾ 2024-05-15 190214.png)

å¯ä»¥å…ˆä½¿ç”¨åŠè‡ªåŠ¨æ ‡æ³¨åŠŸèƒ½å…ˆå°†ç›®æ ‡æ¡†å‡ºï¼Œå†æŒ‰åºæ ‡ç‚¹ã€‚

ä½¿ç”¨pythonè„šæœ¬å°†jsonæ ¼å¼çš„æ ‡æ³¨æ•°æ®è½¬æ¢ä¸ºyoloæ ¼å¼çš„txtæ ‡æ³¨æ•°æ®ï¼š

```python
JSON_DIR = r".\rowdata\uuv_home\row_datasets\json"# åŸæ•°æ®è·¯å¾„
SAVE_DIR = r".\rowdata\uuv_home\row_datasets\txt" # txtæ•°æ®å‚¨å­˜è·¯å¾„
CLASS_NAME = "home" # ç›®æ ‡å
PIONTS_LIST = "front_up_right,front_up_left,front_down_right,front_down_left,back_up_right,back_up_left,back_down_right,back_down_left" # å…³é”®ç‚¹åˆ—è¡¨

import json
import os
from tqdm import tqdm


def get_point(name, shapes) -> dict:
    for shape in shapes:
        if shape["label"] == name:
            return shape
    return None


def convert_label_json(json_dir: str, save_dir: str, class_name: str, points: str):
    json_paths = os.listdir(json_dir)

    points = points.split(",")

    for json_path in tqdm(json_paths):
        # for json_path in json_paths:
        path = os.path.join(json_dir, json_path)
        with open(path, "r") as load_f:
            json_dict = json.load(load_f)
        h, w = json_dict["imageHeight"], json_dict["imageWidth"]

        # save txt path
        txt_path = os.path.join(save_dir, json_path.replace("json", "txt"))
        txt_file = open(txt_path, "w")

        yolo_line = "0 "

        main_box = get_point(class_name, json_dict["shapes"])

        x1 = float(main_box["points"][0][0])
        y1 = float(main_box["points"][0][1])
        x2 = float(main_box["points"][1][0])
        y2 = float(main_box["points"][1][1])

        x_center = (x1 + x2) / 2.0 / w
        y_center = (y1 + y2) / 2.0 / h
        box_w = abs(x2 - x1) / w
        box_h = abs(y2 - y1) / h

        yolo_line += f"{x_center:.6f} {y_center:.6f} {box_w:.6f} {box_h:.6f} "

        for point_name in points:
            point = get_point(point_name, json_dict["shapes"])

            if point is None:
                yolo_line += "0 0 0 "

            else:
                p_x = point["points"][0][0] / w
                p_y = point["points"][0][1] / h
                yolo_line += f"{p_x:.6f} {p_y:.6f} 1 "

        txt_file.writelines(yolo_line)


if __name__ == "__main__":
    convert_label_json(JSON_DIR, SAVE_DIR, CLASS_NAME, PIONTS_LIST)
```

ä½¿ç”¨ **1.1æ•°æ®é›†åˆ¶ä½œ** ä¸­çš„pythonåˆ’åˆ†è„šæœ¬åˆ’åˆ†æ­¤å¤„çš„æ•°æ®é›†ã€‚

### 3.2 æ¨¡å‹è®­ç»ƒ

åˆ›å»ºyamlæ ¼å¼çš„æ•°æ®é›†æè¿°æ–‡ä»¶ï¼š

```yaml
path: ./rowdata/uuv_home/uuv_home
train: images/train # train images
val: images/train # val images
test: images/train # test images (optional)

# å…³é”®ç‚¹
kpt_shape: [8, 3] # [å…³é”®ç‚¹æ•°é‡,å…³é”®ç‚¹åæ ‡ç»´æ•°(2 : x,y | 3 : x,y,visible)]
# flip_idx:  # å¯¹ç§°æ˜ å°„ (å¯é€‰)

# ç›®æ ‡åˆ—è¡¨
names:
  0: uuv_home
```

åˆ›å»ºyamlæ ¼å¼çš„æ¨¡å‹æè¿°æ–‡ä»¶ï¼š

```yaml
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8-pose keypoints/pose estimation model. For Usage examples see https://docs.ultralytics.com/tasks/pose

# Parameters
nc: 1 # ç±»åˆ«æ•°
kpt_shape: [8, 3] # [å…³é”®ç‚¹æ•°é‡,å…³é”®ç‚¹åæ ‡ç»´æ•°(2 : x,y | 3 : x,y,visible)]
scales: # model compound scaling constants, i.e. 'model=yolov8n-pose.yaml' will call yolov8-pose.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]
  s: [0.33, 0.50, 1024]
  m: [0.67, 0.75, 768]
  l: [1.00, 1.00, 512]
  x: [1.00, 1.25, 512]

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
  - [-1, 3, C2f, [512]] # 12

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
  - [-1, 3, C2f, [256]] # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]] # cat head P4
  - [-1, 3, C2f, [512]] # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]] # cat head P5
  - [-1, 3, C2f, [1024]] # 21 (P5/32-large)

  - [[15, 18, 21], 1, Pose, [nc, kpt_shape]] # Pose(P3, P4, P5)
```

ç¼–å†™pythonè„šæœ¬è¿›è¡Œè®­ç»ƒï¼š

```python
DATASET_YAML_PATH = r".\datasets\uuv_home.yaml"
MODEL_YAML_PATH = r".\models\yolov8n-pose.yaml"

SIZE = 640
EPOCHS = 2000

import torch

from ultralytics import YOLO

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")


# æ„å»ºæ¨¡å‹
model = YOLO(MODEL_YAML_PATH)

model.to(device)
model.load("weights/yolov8n-pose.pt")  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹


if __name__ == "__main__":
    # è®­ç»ƒæ¨¡å‹
    results = model.train(data=DATASET_YAML_PATH, epochs=EPOCHS, imgsz=SIZE)

    metrics = model.val()
```



### 3.3 æ¨¡å‹é¢„æµ‹

åŠ è½½æ¨¡å‹å¹¶ä½¿ç”¨gpuå®ç°æ¨¡å‹çš„é¢„æµ‹ï¼š

```python
import torch
from ultralytics import YOLO

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")

# åŠ è½½ YOLOv8 æ¨¡å‹
model = YOLO(r".\weights\uuv_home_pose.pt")
model.to(device)
```

ä½¿ç”¨`model.predict(source=frame)[0]`å¯¹å½“å‰å¸§è¿›è¡Œé¢„æµ‹ï¼š

```python
result = model.predict(source=frame)[0]
```

ä»¥numpyçš„æ ¼å¼æå–æ¨¡å‹é¢„æµ‹ç»“æœï¼š

```python
if result.keypoints is not None:
    keypoints = result.keypoints.cpu().data.numpy()[0]
```

è¯¥ç»“æœä¸ºä¸€ä¸ªç”±n*3çš„numpyçŸ©é˜µï¼Œæ˜¯ä¸€ä¸ªç”±nä¸ªæè¿°å…³é”®ç‚¹ä½ç½®ä¸å¯è§æ€§çš„å‘é‡æŒ‰é¢„è®¾é¡ºåºç»„æˆçš„åˆ—è¡¨ï¼š

å¯æŒ‰ç…§ä»¥ä¸‹æ–¹æ³•é€ä¸ªå†å›¾åƒä¸­æ ‡å‡ºï¼š

```python
for point in keypoints:
    if point[2] > KEYPOINT_SCORE:
        cv2.circle(img,point[0:2].astype(np.int32),3,(0, 255, 0),3,)
```







